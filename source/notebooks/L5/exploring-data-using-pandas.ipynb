{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "# Exploring data using Pandas\n",
    "\n",
    "Our first task in this week's lesson is to learn how to **read and explore data files in Python**. We will focus on using [pandas](https://pandas.pydata.org/pandas-docs/stable/) which is an open-source package for data analysis in Python. Pandas is an excellent toolkit for working with **real world data** that often have a tabular structure (rows and columns).\n",
    "\n",
    "We will first get familiar with **pandas data structures**: *DataFrame* and *Series*:\n",
    "\n",
    "![Pandas data structures](img/pandas-structures.png)\n",
    "\n",
    "- **Pandas DataFrame** (a 2-dimensional data structure) is used for storing and mainpulating table-like data (data with rows and columns) in Python. You can think of pandas DataFrame as a programmable spreadsheet. \n",
    "- **Pandas Series** (a 1-dimensional data structure) is used for storing and manipulating an sequence of values. Pandas Series is kind of like a list, but more clever. One row or one column in a Pandas DataFrame is actually a Pandas Series. \n",
    "\n",
    "These Pandas structures incorporate a number of things we've already encountered, such as indices, data stored in a collection, and data types. Let's have another look at the Pandas data structures below with some additional annotation.\n",
    "\n",
    "![Pandas data structures annotated](img/pandas-structures-annotated.png)\n",
    "\n",
    "As you can see, both DataFrames and Series in pandas have an index that can be used to select values, but they also have column labels to identify columns in DataFrames. In the lesson this week we'll use many of these features to explore real-world data and learn some useful data analysis procedures.\n",
    "\n",
    "For a comprehensive overview of pandas data structures you can have a look at Chapter 5 in Wes MacKinney's book [Python for Data Analysis (2nd Edition, 2017)](https://geo-python.github.io/site/course-info/resources.html#books) and [Pandas online documentation about data structures](https://pandas.pydata.org/pandas-docs/stable/dsintro.html).\n",
    "\n",
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note**\n",
    "    \n",
    "Pandas is a \"high-level\" package, which means that it makes use of several other packages, such as [NumPy](https://numpy.org/), in the background. There are several ways in which data can be read from a file in Python, and this year we have decided to focus primarily on pandas because it is easy-to-use, efficient and intuitive. If you are curoius about other approaches for interacting with data files, you can find lesson materials from previous years about reading data using [NumPy](https://geo-python.github.io/site/2018/notebooks/L5/numpy/1-Exploring-data-using-numpy.html#Reading-a-data-file-with-NumPy) or [built-in Python functions](https://geo-python.github.io/site/2017/lessons/L5/reading-data-from-file.html). \n",
    " \n",
    "</div>\n",
    "\n",
    "\n",
    "## Input data: weather statistics\n",
    "\n",
    "Our input data is a text file containing weather observations from Kumpula, Helsinki, Finland retrieved from [NOAA](https://www.ncdc.noaa.gov/)*:\n",
    "\n",
    "- File name: [Kumpula-June-2016-w-metadata.txt](Kumpula-June-2016-w-metadata.txt)\n",
    "- The file is available in the binder and CSC notebook instances, under L5 folder \n",
    "- The data file contains observed daily mean, minimum, and maximum temperatures from June 2016 recorded from the Kumpula weather observation station in Helsinki.\n",
    "- There are 30 rows of data in this sample data set.\n",
    "- The data has been derived from a data file of daily temperature measurments downloaded from [NOAA](https://www.ncdc.noaa.gov/cdo-web/).\n",
    "\n",
    "\n",
    "\\*US National Oceanographic and Atmospheric Administration's National Centers for Environmental Information climate database\n",
    "\n",
    "## Reading a data file with Pandas\n",
    "\n",
    "\n",
    "Now we're ready to read in our temperature data file. **First, we need to import the Pandas module.** It is customary to import pandas as `pd`:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Next, we'll read the input data file**, and store the contents of that file into a variable called `data` Using the `pandas.read_csv()` function:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Read the file using pandas\n",
    "data = pd.read_csv('Kumpula-June-2016-w-metadata.txt')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Reading data from different formats**\n",
    "    \n",
    "`pandas.read_csv()` is a general function for reading data files separated by commas, spaces, or other common separators. \n",
    "Here we only provided one argument (the filepath) to the `pd.read_csv()` method. For a full list of available parameters, please refer to [pandas documentation for pandas.read_csv](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html), or run `help(pd.read_csv)`.\n",
    "    \n",
    "Pandas has several different functions for parsing input data from different formats. There is, for example, a separate function for reading Excel files `read_excel`. Another useful function is `read_pickle` for reading data stored in the [Python pickle format](https://docs.python.org/3/library/pickle.html). Check out [pandas documentation about input and output functions](https://pandas.pydata.org/pandas-docs/stable/user_guide/io.html#io-tools-text-csv-hdf5) and Chapter 6 in [MacKinney (2017): Python for Data Analysis](https://geo-python.github.io/site/course-info/resources.html#books) for more details about reading data.\n",
    " \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If all goes as planned, you should now have a new variable `data` in memory that contains the input data. You can check the the contents of this variable by calling `data` or `print(data)`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "       # Data file contents: Daily temperatures (mean            min  \\\n",
      "0                 #                     for June 1-30           2016   \n",
      "1   # Data source: https://www.ncdc.noaa.gov/cdo-w...            NaN   \n",
      "2   # Data processing: Extracted temperatures from...   converted to   \n",
      "3           #                  comma-separated format            NaN   \n",
      "4                                                   #            NaN   \n",
      "5                          # David Whipp - 02.10.2017            NaN   \n",
      "6                                            YEARMODA           TEMP   \n",
      "7                                            20160601           65.5   \n",
      "8                                            20160602           65.8   \n",
      "9                                            20160603           68.4   \n",
      "10                                           20160604           57.5   \n",
      "11                                           20160605           51.4   \n",
      "12                                           20160606           52.2   \n",
      "13                                           20160607           56.9   \n",
      "14                                           20160608           54.2   \n",
      "15                                           20160609           49.4   \n",
      "16                                           20160610           49.5   \n",
      "17                                           20160611           54.0   \n",
      "18                                           20160612           55.4   \n",
      "19                                           20160613           58.3   \n",
      "20                                           20160614           59.7   \n",
      "21                                           20160615           63.4   \n",
      "22                                           20160616           57.8   \n",
      "23                                           20160617           60.4   \n",
      "24                                           20160618           57.3   \n",
      "25                                           20160619           56.3   \n",
      "26                                           20160620           59.3   \n",
      "27                                           20160621           62.6   \n",
      "28                                           20160622           61.7   \n",
      "29                                           20160623           60.9   \n",
      "30                                           20160624           61.1   \n",
      "31                                           20160625           65.7   \n",
      "32                                           20160626           69.6   \n",
      "33                                           20160627           60.7   \n",
      "34                                           20160628           65.4   \n",
      "35                                           20160629           65.8   \n",
      "36                                           20160630           65.7   \n",
      "\n",
      "    max) for Kumpula  Helsinki  \n",
      "0                NaN       NaN  \n",
      "1                NaN       NaN  \n",
      "2                NaN       NaN  \n",
      "3                NaN       NaN  \n",
      "4                NaN       NaN  \n",
      "5                NaN       NaN  \n",
      "6                MAX       MIN  \n",
      "7               73.6      54.7  \n",
      "8               80.8      55.0  \n",
      "9                NaN      55.6  \n",
      "10              70.9      47.3  \n",
      "11              58.3      43.2  \n",
      "12              59.7      42.8  \n",
      "13              65.1      45.9  \n",
      "14               NaN      47.5  \n",
      "15              54.1      45.7  \n",
      "16              55.9      43.0  \n",
      "17              62.1      41.7  \n",
      "18              64.2      46.0  \n",
      "19              68.2      47.3  \n",
      "20              67.8      47.8  \n",
      "21              70.3      49.3  \n",
      "22              67.5      55.6  \n",
      "23              70.7      55.9  \n",
      "24               NaN      54.0  \n",
      "25              59.2      54.1  \n",
      "26              69.1      52.2  \n",
      "27              71.4      50.4  \n",
      "28              70.2      55.4  \n",
      "29              67.1      54.9  \n",
      "30              68.9      56.7  \n",
      "31              75.4      57.9  \n",
      "32              77.7      60.3  \n",
      "33              70.0       NaN  \n",
      "34              73.0      55.8  \n",
      "35              73.2       NaN  \n",
      "36              72.7      59.2  \n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "This looks OK, but there are some strange values present such as `NaN`, and the first lines of the dataframe look a bit weird.. \n",
    "\n",
    "`NaN` stands for \"not a number\", and might indicate some problem with reading in the contents of the file. Plus, we expected about 30 lines of data, but the index values go up to 36 when we print the contents of the `data` variable. Looks like we need to investigate this further."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "As we can observe, there are some metadata at the top of the file giving basic information about its contents and source. This isn't data we want to process, so we need to skip over that part of the file when we load it.\n",
    "\n",
    "Here are the 8 first rows of data in the text file (note that the 8th row is blank):"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "```\n",
    "# Data file contents: Daily temperatures (mean, min, max) for Kumpula, Helsinki\n",
    "#                     for June 1-30, 2016\n",
    "# Data source: https://www.ncdc.noaa.gov/cdo-web/search?datasetid=GHCND\n",
    "# Data processing: Extracted temperatures from raw data file, converted to\n",
    "#                  comma-separated format\n",
    "#\n",
    "# David Whipp - 02.10.2017\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Fortunately, that's easy to do in pandas, we just need to add the `skiprows` parameter when we read the file, listing the number of rows to skip (8 in this case).\n",
    "\n",
    "Let's try reading the datafile again, and this time defining the `skiprows` parameter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Kumpula-June-2016-w-metadata.txt', skiprows=8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Let's now print the dataframe and see what changed:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEARMODA  TEMP   MAX   MIN\n",
      "0   20160601  65.5  73.6  54.7\n",
      "1   20160602  65.8  80.8  55.0\n",
      "2   20160603  68.4   NaN  55.6\n",
      "3   20160604  57.5  70.9  47.3\n",
      "4   20160605  51.4  58.3  43.2\n",
      "5   20160606  52.2  59.7  42.8\n",
      "6   20160607  56.9  65.1  45.9\n",
      "7   20160608  54.2   NaN  47.5\n",
      "8   20160609  49.4  54.1  45.7\n",
      "9   20160610  49.5  55.9  43.0\n",
      "10  20160611  54.0  62.1  41.7\n",
      "11  20160612  55.4  64.2  46.0\n",
      "12  20160613  58.3  68.2  47.3\n",
      "13  20160614  59.7  67.8  47.8\n",
      "14  20160615  63.4  70.3  49.3\n",
      "15  20160616  57.8  67.5  55.6\n",
      "16  20160617  60.4  70.7  55.9\n",
      "17  20160618  57.3   NaN  54.0\n",
      "18  20160619  56.3  59.2  54.1\n",
      "19  20160620  59.3  69.1  52.2\n",
      "20  20160621  62.6  71.4  50.4\n",
      "21  20160622  61.7  70.2  55.4\n",
      "22  20160623  60.9  67.1  54.9\n",
      "23  20160624  61.1  68.9  56.7\n",
      "24  20160625  65.7  75.4  57.9\n",
      "25  20160626  69.6  77.7  60.3\n",
      "26  20160627  60.7  70.0   NaN\n",
      "27  20160628  65.4  73.0  55.8\n",
      "28  20160629  65.8  73.2   NaN\n",
      "29  20160630  65.7  72.7  59.2\n"
     ]
    }
   ],
   "source": [
    "print(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "After reading in the data, it is always good to check that everything went well (like we just did with the print-statement above). The challenge can also be that large datafiles might not nicely print on screen using the `print()`-function so it might be better to look at only the top 5-10 lines of the file rather than loading the entire thing. \n",
    "\n",
    "We can  use `pandas.DataFrame.head` to quickly check the contents of the dataframe. This method returns the first n rows for the dataframe. By default, it returns 5 first rows of the DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEARMODA</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>20160601</td>\n",
       "      <td>65.5</td>\n",
       "      <td>73.6</td>\n",
       "      <td>54.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20160602</td>\n",
       "      <td>65.8</td>\n",
       "      <td>80.8</td>\n",
       "      <td>55.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>20160603</td>\n",
       "      <td>68.4</td>\n",
       "      <td>NaN</td>\n",
       "      <td>55.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>20160604</td>\n",
       "      <td>57.5</td>\n",
       "      <td>70.9</td>\n",
       "      <td>47.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20160605</td>\n",
       "      <td>51.4</td>\n",
       "      <td>58.3</td>\n",
       "      <td>43.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   YEARMODA  TEMP   MAX   MIN\n",
       "0  20160601  65.5  73.6  54.7\n",
       "1  20160602  65.8  80.8  55.0\n",
       "2  20160603  68.4   NaN  55.6\n",
       "3  20160604  57.5  70.9  47.3\n",
       "4  20160605  51.4  58.3  43.2"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can also check the last rows of the data using `data.tail()`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>YEARMODA</th>\n",
       "      <th>TEMP</th>\n",
       "      <th>MAX</th>\n",
       "      <th>MIN</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>20160626</td>\n",
       "      <td>69.6</td>\n",
       "      <td>77.7</td>\n",
       "      <td>60.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>20160627</td>\n",
       "      <td>60.7</td>\n",
       "      <td>70.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>20160628</td>\n",
       "      <td>65.4</td>\n",
       "      <td>73.0</td>\n",
       "      <td>55.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>20160629</td>\n",
       "      <td>65.8</td>\n",
       "      <td>73.2</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>20160630</td>\n",
       "      <td>65.7</td>\n",
       "      <td>72.7</td>\n",
       "      <td>59.2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    YEARMODA  TEMP   MAX   MIN\n",
       "25  20160626  69.6  77.7  60.3\n",
       "26  20160627  60.7  70.0   NaN\n",
       "27  20160628  65.4  73.0  55.8\n",
       "28  20160629  65.8  73.2   NaN\n",
       "29  20160630  65.7  72.7  59.2"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Note that Pandas that DataFrames have **labelled axes (rows and columns)**.  In our sample data, the rows labeled with an index value (`0` to `29`), and columns labelled `YEARMODA`, `TEMP`, `MAX`, and `MIN`. Later on, we will learn how to use these labels for selecting and updating subsets of the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Let's also confirm the data type of our data variable:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "pandas.core.frame.DataFrame"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "No surprises here, our data variable is a Pandas DataFrame ;)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Check your understanding\n",
    "\n",
    "Read in the file again into a new variable called `temp_data` so that you only read in columns `YEARMODA` and `TEMP`. The new variable `temp_data` should have 30 rows and 2 columns. You can check for help in the [pandas.read_csv documentation](https://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note**\n",
    "\n",
    " We can use [IPython magic commands](https://ipython.readthedocs.io/en/stable/interactive/magics.html#line-magics) to figure out what variables we have in memory. IPython magic command `%who` will display names of those variables that you have defined during this session. Magic command `%whose` prints out more information about these variables.\n",
    "    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Display variable names:\n",
    "%who"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display variable name, type and info\n",
    "%whos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## DataFrame properties\n",
    "\n",
    "We now have some basic Python skills and the ability to read in data from a file for processing. A normal first step when you load new data is to explore the dataset a bit to understand how the data is structured, and what kind of values are stored in there."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's start by checking the size of our data frame. We can use the `len()` function similarly as with lists to check how many rows we have:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Check the number of rows using len()-function\n",
    "len(data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can also get a quick sense of the size of the dataset using the `shape` attribute.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(30, 4)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Check dataframe shape (number of rows, number of columns)\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here we see that our dataset has 30 rows, 4 columns, just as we saw above when printing out the whole DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**We can also check the column names we have in our DataFrame.** We already saw the column names when we checked the 5 first rows using `data.head()`, but often it is useful to access only the column names. You can call `data.columns` (returns the an index object) or `data.columns.values` (returns a list of column values) to check the column names:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['YEARMODA', 'TEMP', 'MAX', 'MIN'], dtype=object)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print column values\n",
    "data.columns.values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can also find information about the row identifiers using the `index` attribute:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=30, step=1)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Print index\n",
    "data.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here we see how the data is indexed, starting at 0, ending at 30, and with an increment of 1 between each value. This is basically the same way in which Python lists are indexed, however, pandas allows also other ways of identifying the rows. DataFrame indices could, for example, be character strings, or date objects (you will learn more about re-setting the index later). Eventually, the \"length\" of the DataFrame (the number of rows) is actually the length of the index:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Check length of the index\n",
    "len(data.index)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "What about the data types of each column in our dataFrame? We can check the data type of all the columns at once using `pandas.DataFrame.dtypes`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "YEARMODA      int64\n",
       "TEMP        float64\n",
       "MAX         float64\n",
       "MIN         float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Print data types\n",
    "data.dtypes"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Here we see that `YEARMODA` is an integer value (with 64-bit precision; int64), while the other values are all decimal values with 64-bit precision (float64)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Selecting columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In pandas, we select columns based on the column values (columns names). The basic syntax is `dataframe[value]`, where value can be a single column name, or a list of column names. Let's start by selecting two columns, `'YEARMODA'` and `'TEMP'`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    YEARMODA  TEMP\n",
      "0   20160601  65.5\n",
      "1   20160602  65.8\n",
      "2   20160603  68.4\n",
      "3   20160604  57.5\n",
      "4   20160605  51.4\n",
      "5   20160606  52.2\n",
      "6   20160607  56.9\n",
      "7   20160608  54.2\n",
      "8   20160609  49.4\n",
      "9   20160610  49.5\n",
      "10  20160611  54.0\n",
      "11  20160612  55.4\n",
      "12  20160613  58.3\n",
      "13  20160614  59.7\n",
      "14  20160615  63.4\n",
      "15  20160616  57.8\n",
      "16  20160617  60.4\n",
      "17  20160618  57.3\n",
      "18  20160619  56.3\n",
      "19  20160620  59.3\n",
      "20  20160621  62.6\n",
      "21  20160622  61.7\n",
      "22  20160623  60.9\n",
      "23  20160624  61.1\n",
      "24  20160625  65.7\n",
      "25  20160626  69.6\n",
      "26  20160627  60.7\n",
      "27  20160628  65.4\n",
      "28  20160629  65.8\n",
      "29  20160630  65.7\n"
     ]
    }
   ],
   "source": [
    "selection = data[['YEARMODA','TEMP']]\n",
    "print(selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's also check the data type of this selection:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(selection)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The subset is still a pandas DataFrame, and we are able to use all the methods related to a pandas DataFrame also with this subset. For example, we can check the shape:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "selection.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "We can also access a single column of the data based on the column name:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "data['TEMP']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What about the type of the column itself?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Check datatype of the column\n",
    "type(data['TEMP'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "**Each column (and each row) in a pandas data frame is actually a pandas Series** - a 1 dimensional data structure!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-info\">\n",
    "\n",
    "**Note**\n",
    "\n",
    "You can also retreive a column using a different syntax:\n",
    "    \n",
    "``` \n",
    "data.TEMP\n",
    "```\n",
    "This syntax works only if the column name is a valid name for a Python variable (e.g. the column name should not contain whitespace).\n",
    "The syntax `data[\"column\"]` works for all kinds of column names, so we recommend using this approach :)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(data.TEMP)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descriptive statistics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Pandas DataFrames and Series contain useful methods for getting summary statistics. Available methods include `mean()`, `median()`, `min()`, `max()`, and `std()` (the standard deviation)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We could, for example, check the mean temperature in our input data. We check the mean for a single column (*Series*): "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Check mean value of a column\n",
    "data['TEMP'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "and for all columns (in the *DataFrame*):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check mean value for all columns\n",
    "data.mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "For an overview of the basic statistics for all attributes in the data, we can use the `describe()` method:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Get descriptive statistics\n",
    "data.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extra: Very basic plots"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Pandas comes with a handful of plotting methods, which all rely on the plotting library [matplotlib](https://matplotlib.org/). "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For very basic plots, we don’t need to import matplotlib separately, but we need to run a magic command %matplotlib inline in order to make the plots visible in our notebook:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can already achieve very simple plots using the `DataFrame.plot` -method. Let's plot all the columns that contain values related to temperatures:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[[\"TEMP\", \"MAX\", \"MIN\"]].plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now you might want to start modifying the plot by adding axis labels, color settings and other formatting. For anythin more advanced, we should import matplotlib (`import matplotlib.pyplot as plt`). We will learn more about matplotlib and plotting data during week 7."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "## Extra: From lists to pandas objects\n",
    "\n",
    "Most often we create pandas objects by reading in data from an external source, such as a text file. Here, we will briefly see how you can create pandas objects from Python lists. If you have long lists of numbers, for instance, creating a Pandas Series will allow you to interact with these values more efficiently in terms of computing time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "deletable": true,
    "editable": true,
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "outputs": [],
   "source": [
    "# Create Pandas Series from a list\n",
    "number_series = pd.Series([ 4, 5, 6, 7.0])\n",
    "print(number_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "Note that Pandas is smart about the conversion, detecting a single floating point value (`7.0`) and assigning all values in the Series the data type float64."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If needed, you can also set a custom index when creating the object:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number_series = pd.Series([ 4, 5, 6, 7.0], index=['a','b','c','d'])\n",
    "print(number_series)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(number_series)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How about combining several lists as a DataFrame? Let's take a subset of the lists we used in Exercise 3, problem 3 and see how we could combine those as a pandas DataFrame:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Station names\n",
    "stations = ['Hanko Russarö', 'Heinola Asemantaus', 'Helsinki Kaisaniemi', 'Helsinki Malmi airfield']\n",
    "\n",
    "# Latitude coordinates of Weather stations  \n",
    "lats = [59.77, 61.2, 60.18, 60.25]\n",
    "\n",
    "# Longitude coordinates of Weather stations \n",
    "lons = [22.95, 26.05, 24.94, 25.05]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often we indeed create pandas DataFrames by reading in data (e.g. using `pd.read_csv(filename.csv)`), but sometimes your might also combine lists into a DataFrame inside the script using the `pandas.DataFrame` constructor. Here, we are using a *Python dictionary* `{\"column_1\": list_1, \"column_2\": list_2, ...}` to indicate the structure of our data. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_data = pd.DataFrame(data = {\"station_name\" : stations, \"lat\" : lats, \"lon\" : lons})\n",
    "new_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(new_data)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Often, you might start working with an empty data frame in stead of existing lists:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check more details about available paramenters and methods from [the pandas.DataFrame documentation](https://pandas.pydata.org/pandas-docs/stable/reference/api/pandas.DataFrame.html#pandas-dataframe)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "deletable": true,
    "editable": true
   },
   "source": [
    "That's it! Next, we will have a look at [basic operations for data analysis in Pandas](processing-data-with-pandas.ipynb)."
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
